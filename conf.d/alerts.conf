input {
  kafka
    {
            bootstrap_servers => "kafka-d01.maeagle.corp:9092"
            client_id => "logstash_alerts"
            group_id => "logstash_alerts"
            topics_pattern => "(prod|staging|dev|poc)-(pymsa|erpc|erph)-alerts-log$"
            enable_auto_commit => false
            decorate_events => true
            poll_timeout_ms => "20000"
            auto_offset_reset => "earliest"
    }
}

filter{
      json  {
          source => "message"
      }

      ruby {
          code => "
              event.set('kafka_metadata', event.get('@metadata'))
              event.set('[@metadata][index_log_date]', event.get('datetime')[0..9])
              event.set('app_group', event.get('[kafka_metadata][kafka][topic]').split('-')[1])
          "
      }

      environment { 
          add_metadata_from_env => { "hostname" => "HOSTNAME" }
      }

      mutate  {
          add_field    => {"kafka_unix" => "%{[kafka_metadata][kafka][timestamp]}"}
          add_field    => {"logstash_timestamp" => "%{@timestamp}"}
          add_tag      => ["%{[@metadata][hostname]}"]
      }      
      
      date {
          # locale => "en"
          match => ["kafka_unix", "UNIX_MS"]
          timezone => "UTC"
          target => "kafka_timestamp"
      } 
      
      date {
          # locale => "en"
          match => ["datetime", "ISO8601"]
          timezone => "UTC"
          target => "@timestamp"
      }
      
      if [env] == "prod"{
          mutate {  
              add_field => {"[@metadata][index_env]" => ""}
              remove_field => ["env"]
          }
      }
      else  {
          mutate {  add_field => {"[@metadata][index_env]" => "%{env}::"}  }
      }

}

output {
    elasticsearch {
        action => "index"
        hosts => "elasticlog-p01:9200"       
        index => "%{app_group}::alerts::%{[@metadata][index_env]}%{[@metadata][index_log_date]}"
    }

    file {
        path => "/var/log/logstash/logstash-alerts.log"
    }
}